{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing Libraries**"
      ],
      "metadata": {
        "id": "o9Fw_kY_ZAPE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fs1fp9EVY7iL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "#math operations\n",
        "import numpy as np\n",
        "#machine learning\n",
        "import cv2\n",
        "import os\n",
        "from random import shuffle\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "#for opening and loading image\n",
        "from PIL import Image\n",
        "#for preprocessing\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "#Doing One hot encoding as classifier has multiple classes\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from random import shuffle\n",
        "#For augmentation\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "#MobileNetV2 model\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from tensorflow.keras import Model, layers\n",
        "from numpy import loadtxt\n",
        "\n",
        "import itertools\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "\n",
        "from tensorflow.keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Mounting Google drive**"
      ],
      "metadata": {
        "id": "_mvtOAUdZJdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "n74-OTo9ZItU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading saved Train data and labels**"
      ],
      "metadata": {
        "id": "MDh02obIZYHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feats=np.load(\"/content/drive/My Drive/skin_cancer_dataset/check_points/demo_feats_train.npy\")\n",
        "labels=np.load(\"/content/drive/My Drive/skin_cancer_dataset/check_points/demo_labels_train.npy\")"
      ],
      "metadata": {
        "id": "0trfFlr1ZgDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Randomizing Data and Labels**"
      ],
      "metadata": {
        "id": "o8Y0gkS7ZiUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s=np.arange(feats.shape[0])\n",
        "np.random.shuffle(s)\n",
        "feats=feats[s]\n",
        "labels=labels[s]"
      ],
      "metadata": {
        "id": "KKTYOJjrZqsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes=len(np.unique(labels))\n",
        "len_data=len(feats)\n",
        "print(len_data)\n",
        "print(num_classes)"
      ],
      "metadata": {
        "id": "Rp-x50G_ZwfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train Test Split**"
      ],
      "metadata": {
        "id": "XsLC8M4VZz_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting cells images into 80:20 ratio i.e., 80% for training and 20% for testing purpose\n",
        "(x_train,x_test)=feats[(int)(0.2*len_data):],feats[:(int)(0.2*len_data)]\n",
        "\n",
        "(y_train,y_test)=labels[(int)(0.2*len_data):],labels[:(int)(0.2*len_data)]"
      ],
      "metadata": {
        "id": "VVf8XXgTZ42a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Image Data Normalization**"
      ],
      "metadata": {
        "id": "fvlFZm2baCQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32')/255 # As we are working on image data we are normalizing data by dividing 255.\n",
        "x_test = x_test.astype('float32')/255\n",
        "train_len=len(x_train)\n",
        "test_len=len(x_test)"
      ],
      "metadata": {
        "id": "03aOaWccaFh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train=to_categorical(y_train,5)\n",
        "y_test=to_categorical(y_test,5)"
      ],
      "metadata": {
        "id": "vplLgtkTaHR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Image Augmentation**"
      ],
      "metadata": {
        "id": "AV7WGmLpaKJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainAug  = ImageDataGenerator(\n",
        "featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=False,  # randomly flip images\n",
        "        vertical_flip=False)"
      ],
      "metadata": {
        "id": "nX0uBT0_aOWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Building**"
      ],
      "metadata": {
        "id": "EkKiRAc6aSme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base = MobileNetV2(\n",
        "    include_top=False,\n",
        "    input_shape=(224, 224, 3),\n",
        "    weights='imagenet')\n",
        "\n",
        "for layer in conv_base.layers:\n",
        "    layer.trainable = True"
      ],
      "metadata": {
        "id": "nFl5qVfPaXIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = conv_base.output\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dense(256, activation='relu')(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "predictions = layers.Dense(5, activation='softmax')(x)\n",
        "model = Model(conv_base.input, predictions)"
      ],
      "metadata": {
        "id": "16zKeNOhaZyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [ModelCheckpoint('.mdl_wts.hdf5', monitor='val_loss',mode='min',verbose=1, save_best_only=True),\n",
        "             ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=2, verbose=1, mode='min', min_lr=0.00000000001)]"
      ],
      "metadata": {
        "id": "wwY0_BJDabht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "BS = 32\n",
        "print(\"[INFO] training head...\")\n",
        "H = model.fit(\n",
        "\ttrainAug.flow(x_train,y_train, batch_size=BS),\n",
        "\tsteps_per_epoch=train_len // BS,\n",
        "\tvalidation_data=(x_test, y_test),\n",
        "\tvalidation_steps=test_len // BS,\n",
        "\tepochs=60,callbacks=callbacks)"
      ],
      "metadata": {
        "id": "xEMvk598acwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Saving and Loading Model**"
      ],
      "metadata": {
        "id": "jlTSzU4vaia1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('.mdl_wts.hdf5')\n",
        "model.save('/content/drive/My Drive/skin_cancer_dataset/check_points/5demo_model_v1.h5')\n"
      ],
      "metadata": {
        "id": "l8XcHOApahS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('/content/drive/My Drive/skin_cancer_dataset/check_points/5demo_model_v1.h5')\n",
        "# checking the accuracy\n",
        "accuracy = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('\\n', 'Test_Accuracy:-', accuracy[1])"
      ],
      "metadata": {
        "id": "yc8kndeaamGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rounded_predictions = model.predict(x_test, batch_size=16, verbose=0)\n",
        "rounded_predictions[1]"
      ],
      "metadata": {
        "id": "4akxxnMnap6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Plotting Confusion Matrix**"
      ],
      "metadata": {
        "id": "pOuuX7Oqa1j7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred = np.argmax(rounded_predictions,axis=1)\n",
        "rounded_labels=np.argmax(y_test, axis=1)\n",
        "\n",
        "pred_Y = model.predict(x_test, batch_size = 16, verbose = True)\n",
        "BS=16\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    target_names =['BCC','Melanoma','Nevus','Benign_keratosis','No_cancer']\n",
        "\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "# Predict the values from the validation dataset\n",
        "Y_pred = model.predict(x_test, batch_size=BS)\n",
        "# Convert predictions classes to one hot vectors\n",
        "Y_pred_classes = np.argmax(pred_Y,axis=1)\n",
        "# Convert validation observations to one hot vectors\n",
        "# compute the confusion matrix\n",
        "rounded_labels=np.argmax(y_test, axis=1)\n",
        "confusion_mtx = confusion_matrix(rounded_labels, Y_pred_classes)\n",
        "\n",
        "\n",
        "\n",
        "# plot the confusion matrix\n",
        "plot_confusion_matrix(confusion_mtx, classes = range(3))"
      ],
      "metadata": {
        "id": "HV1cJmDIar20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predIdxs = model.predict(x_test, batch_size=BS)\n",
        "\n",
        "# for each image in the testing set we need to find the index of the\n",
        "# label with corresponding largest predicted probability\n",
        "predIdxs = np.argmax(predIdxs, axis=1)\n",
        "rounded_labels=np.argmax(y_test, axis=1)\n",
        "\n",
        "# show a nicely formatted classification report\n",
        "print(classification_report(rounded_labels, predIdxs,target_names=['BCC','Melanoma','Nevus','Benign_keratosis','No_cancer']))"
      ],
      "metadata": {
        "id": "yuPbPp5xa7n8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Plotting ROC AUC**"
      ],
      "metadata": {
        "id": "MGxHu8aha9PD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "\n",
        "\n",
        "from itertools import cycle\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "n_classes = 5\n",
        "\n",
        "pred_Y = model.predict(x_test, batch_size = 16, verbose = True)\n",
        "# Plot linewidth.\n",
        "lw = 2\n",
        "\n",
        "# Compute ROC curve and ROC area for each class\n",
        "\n",
        "\n",
        "# Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], pred_Y[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "    # Compute micro-average ROC curve and ROC area\n",
        "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), pred_Y.ravel())\n",
        "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "# Plot of a ROC curve for a specific class\n",
        "for i in range(n_classes):\n",
        "    plt.figure()\n",
        "    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic example')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "# First aggregate all false positive rates\n",
        "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
        "\n",
        "# Then interpolate all ROC curves at this points\n",
        "mean_tpr = np.zeros_like(all_fpr)\n",
        "for i in range(n_classes):\n",
        "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
        "\n",
        "# Finally average it and compute AUC\n",
        "mean_tpr /= n_classes\n",
        "\n",
        "fpr[\"macro\"] = all_fpr\n",
        "tpr[\"macro\"] = mean_tpr\n",
        "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "# Plot all ROC curves\n",
        "fig = plt.figure(figsize=(12, 8))\n",
        "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "         label='micro-average ROC curve (area = {0:0.2f})'\n",
        "               ''.format(roc_auc[\"micro\"]),\n",
        "         color='deeppink', linestyle=':', linewidth=4)\n",
        "\n",
        "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
        "         label='macro-average ROC curve (area = {0:0.2f})'\n",
        "               ''.format(roc_auc[\"macro\"]),\n",
        "         color='navy', linestyle=':', linewidth=4)\n",
        "\n",
        "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
        "for i, color in zip(range(n_classes), colors):\n",
        "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
        "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "             ''.format(i, roc_auc[i]))\n",
        "\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
        "plt.legend(loc=\"lower right\")\n",
        "sns.despine()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zBgn-rCtbDdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading saved Test data and labels**"
      ],
      "metadata": {
        "id": "5IQJHs43bOAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feats_test=np.load(\"/content/drive/My Drive/skin_cancer_dataset/check_points/demo_feats_test.npy\")\n",
        "labels_test=np.load(\"/content/drive/My Drive/skin_cancer_dataset/check_points/demo_labels_test.npy\")\n",
        "\n",
        "num_classes=len(np.unique(labels_test))\n",
        "len_data=len(feats_test)\n",
        "print(len_data)"
      ],
      "metadata": {
        "id": "QwhrW0rzbP0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_valid = feats_test.astype('float32')/255\n",
        "y_valid=to_categorical(labels_test,5)"
      ],
      "metadata": {
        "id": "u8OKcvxQbUy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_Y = model.predict(x_valid, batch_size = 10, verbose = True)\n",
        "rounded_predictions = model.predict(x_valid, batch_size=16, verbose=0)\n",
        "pred = np.argmax(rounded_predictions,axis=1)\n",
        "rounded_labels=np.argmax(y_valid, axis=1)\n",
        "BS=10\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    target_names =['BCC','Melanoma','Nevus','Benign_keratosis','No_cancer']\n",
        "\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "# Predict the values from the validation dataset\n",
        "Y_pred = model.predict(x_valid, batch_size=BS)\n",
        "# Convert predictions classes to one hot vectors\n",
        "Y_pred_classes = np.argmax(pred_Y,axis=1)\n",
        "# Convert validation observations to one hot vectors\n",
        "# compute the confusion matrix\n",
        "rounded_labels=np.argmax(y_valid, axis=1)\n",
        "confusion_mtx = confusion_matrix(rounded_labels, Y_pred_classes)\n",
        "# plot the confusion matrix\n",
        "plot_confusion_matrix(confusion_mtx, classes = range(3))"
      ],
      "metadata": {
        "id": "WPDHfOASbW5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Usage**"
      ],
      "metadata": {
        "id": "sK0Sse__be0l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_dict ={\"Basal_Cell_Carcinoma\":0,\n",
        "             \"Melanoma\":1,\n",
        "             \"Nevus\":2,\n",
        "             \"Benign_keratosis\":3,\n",
        "             \"No_cancer\":4}"
      ],
      "metadata": {
        "id": "aXE3M34dbqJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "from IPython.display import display\n",
        "import numpy as np\n",
        "\n",
        "def pred_image(img_path, model, class_dict):\n",
        "    img = Image.open(img_path).resize((224,224)) #target_size must agree with what the trained model expects!!\n",
        "\n",
        "    # Preprocessing the image\n",
        "    img = image.img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = img.astype('float32')/255\n",
        "\n",
        "    preds = model.predict(img)[0] # Extracting the predictions for the first (and only) image\n",
        "    pred_class = np.argmax(preds)\n",
        "    pred_cat = [k for k, v in class_dict.items() if v == pred_class][0]\n",
        "\n",
        "    confidence = preds[pred_class] * 100\n",
        "    other_confidences = [preds[i] * 100 for i in range(len(preds)) if i != pred_class]\n",
        "\n",
        "    return pred_cat, confidence, other_confidences\n"
      ],
      "metadata": {
        "id": "rwPfLMHfbr5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = \"/content/drive/My Drive/skin_cancer_dataset/ISIC_demo_Input/Basal_Cell_Carcinoma/test/bcc_ISIC_0024931.jpg\"\n",
        "pred_cat, confidence, other_confidences = pred_image(img_path, model, class_dict)\n",
        "print(\"Predicted class:\", pred_cat)\n",
        "print(\"Confidence:\", confidence, \"%\")\n",
        "print(\"Confidence with respect to other classes:\", other_confidences)"
      ],
      "metadata": {
        "id": "r49t_1n3bwTr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}